================================================================================
                    HUMAN-IN-THE-LOOP DRIFT DETECTION PIPELINE
                         MODULES & FUNCTIONS REFERENCE
================================================================================

This document describes all Python modules used in the project, their purpose,
and the key functions/classes utilized from each module.

================================================================================
                              STANDARD LIBRARY MODULES
================================================================================

1. OS (os)
   ------------------------------------------------------------------------
   Purpose: Operating system interface for file/directory operations
   
   Functions Used:
   - os.path.join()        : Join path components (platform-independent)
   - os.path.exists()      : Check if a file/directory exists
   - os.path.dirname()     : Get directory name from path
   - os.path.abspath()     : Get absolute path
   - os.makedirs()         : Create directories recursively
   - os.environ            : Access/modify environment variables
   
   Used In: All Python files

--------------------------------------------------------------------------------

2. SYS (sys)
   ------------------------------------------------------------------------
   Purpose: System-specific parameters and functions
   
   Functions Used:
   - sys.argv              : Command-line arguments list
   - sys.executable        : Path to Python interpreter
   
   Used In: detect_drift.py, web_pipeline.py

--------------------------------------------------------------------------------

3. JSON (json)
   ------------------------------------------------------------------------
   Purpose: JSON encoding and decoding
   
   Functions Used:
   - json.load()           : Parse JSON from file
   - json.dumps()          : Convert Python object to JSON string
   
   Used In: web_pipeline.py

--------------------------------------------------------------------------------

4. BASE64 (base64)
   ------------------------------------------------------------------------
   Purpose: Encode binary data to ASCII (for embedding images in HTML)
   
   Functions Used:
   - base64.b64encode()    : Encode bytes to base64
   - .decode('utf-8')      : Convert bytes to string
   
   Used In: detect_drift.py, web_pipeline.py
   
   Why: Embed PNG visualizations directly into HTML reports without external files

--------------------------------------------------------------------------------

5. WEBBROWSER (webbrowser)
   ------------------------------------------------------------------------
   Purpose: Open URLs in web browser
   
   Functions Used:
   - webbrowser.open()     : Open URL in default browser
   
   Used In: detect_drift.py, web_pipeline.py
   
   Why: Automatically open HTML reports and web dashboard

--------------------------------------------------------------------------------

6. SUBPROCESS (subprocess)
   ------------------------------------------------------------------------
   Purpose: Spawn new processes and run external commands
   
   Functions Used:
   - subprocess.run()      : Run command and wait for completion
   
   Used In: web_pipeline.py
   
   Why: Execute Python scripts (detect_drift.py, retrain_model.py) from web interface

--------------------------------------------------------------------------------

7. SHUTIL (shutil)
   ------------------------------------------------------------------------
   Purpose: High-level file operations
   
   Functions Used:
   - shutil.copy()         : Copy file to destination
   
   Used In: retrain_model.py, web_pipeline.py
   
   Why: Copy current.csv to reference.csv after retraining

--------------------------------------------------------------------------------

8. HTTP.SERVER (http.server)
   ------------------------------------------------------------------------
   Purpose: Built-in HTTP server functionality
   
   Classes Used:
   - HTTPServer            : HTTP server class
   - SimpleHTTPRequestHandler : Base handler for HTTP requests
   
   Used In: web_pipeline.py
   
   Why: Create local web server for interactive dashboard without external dependencies

--------------------------------------------------------------------------------

9. URLLIB.PARSE (urllib.parse)
   ------------------------------------------------------------------------
   Purpose: Parse URLs and query strings
   
   Functions Used:
   - parse_qs()            : Parse query string to dictionary
   
   Used In: web_pipeline.py


================================================================================
                          THIRD-PARTY DATA SCIENCE MODULES
================================================================================

10. PANDAS (pandas)
    ------------------------------------------------------------------------
    Purpose: Data manipulation and analysis with DataFrames
    
    Functions/Methods Used:
    - pd.read_csv()        : Read CSV file into DataFrame
    - pd.to_numeric()      : Convert to numeric type
    - pd.get_dummies()     : One-hot encoding for categorical variables
    - pd.concat()          : Concatenate DataFrames
    - pd.Timestamp.now()   : Get current timestamp
    - df.drop()            : Remove columns/rows
    - df.dropna()          : Remove rows with missing values
    - df.copy()            : Create DataFrame copy
    - df.iloc[]            : Integer-location based indexing
    - df.sort_values()     : Sort by column values
    - df.to_csv()          : Save DataFrame to CSV
    - df.select_dtypes()   : Select columns by data type
    - df.std()             : Calculate standard deviation
    
    Used In: All Python files
    
    Why: Core library for loading, cleaning, transforming, and saving tabular data

--------------------------------------------------------------------------------

11. NUMPY (numpy)
    ------------------------------------------------------------------------
    Purpose: Numerical computing with arrays
    
    Functions Used:
    - np.random.uniform()  : Generate random numbers from uniform distribution
    - np.random.seed()     : Set random seed for reproducibility
    
    Used In: web_pipeline.py, preprocess.py
    
    Why: Generate synthetic data variations for drift simulation in demo mode

--------------------------------------------------------------------------------

12. MATPLOTLIB (matplotlib.pyplot)
    ------------------------------------------------------------------------
    Purpose: Static visualization library for creating charts
    
    Functions/Methods Used:
    - plt.figure()         : Create new figure
    - plt.style.use()      : Set plot style theme
    - plt.savefig()        : Save figure to file
    - plt.close()          : Close figure to free memory
    - plt.tight_layout()   : Adjust subplot parameters for tight layout
    - fig.add_subplot()    : Add subplot to figure
    - fig.suptitle()       : Add super title to figure
    - ax.pie()             : Create pie chart
    - ax.bar()             : Create bar chart
    - ax.barh()            : Create horizontal bar chart
    - ax.axvline()         : Add vertical line
    - ax.set_title()       : Set axis title
    - ax.set_xlabel()      : Set x-axis label
    - ax.set_ylabel()      : Set y-axis label
    - ax.set_xlim()        : Set x-axis limits
    - ax.set_ylim()        : Set y-axis limits
    - ax.legend()          : Add legend
    - ax.text()            : Add text annotation
    - ax.spines            : Access axis borders
    
    Used In: detect_drift.py
    
    Why: Create visual drift analysis dashboard with pie charts, bar charts, 
         threshold gauges, and distribution comparison plots

--------------------------------------------------------------------------------

13. MATPLOTLIB.GRIDSPEC (GridSpec)
    ------------------------------------------------------------------------
    Purpose: Flexible grid layout for subplots
    
    Classes Used:
    - GridSpec             : Create grid specification for subplots
    
    Used In: detect_drift.py
    
    Why: Create custom layout with 3 summary charts in row 1, and 3 distribution
         plots per row in subsequent rows

--------------------------------------------------------------------------------

14. SEABORN (seaborn)
    ------------------------------------------------------------------------
    Purpose: Statistical data visualization (built on matplotlib)
    
    Functions Used:
    - sns.set_palette()    : Set color palette for plots
    - sns.kdeplot()        : Kernel density estimation plot
    
    Used In: detect_drift.py
    
    Why: Create smooth density distribution plots comparing reference vs current
         data with filled areas and professional styling


================================================================================
                          MACHINE LEARNING MODULES
================================================================================

15. SCIKIT-LEARN (sklearn)
    ------------------------------------------------------------------------
    Purpose: Machine learning library for model training and evaluation
    
    Classes/Functions Used:
    
    From sklearn.ensemble:
    - RandomForestClassifier : Ensemble classifier using decision trees
      Methods: .fit(), .predict(), .predict_proba()
    
    From sklearn.model_selection:
    - train_test_split()    : Split data into train/test sets
    
    From sklearn.metrics:
    - roc_auc_score()       : Calculate ROC-AUC metric
    
    Used In: train.py, retrain_model.py
    
    Why: Train customer churn prediction model using Random Forest algorithm,
         evaluate model performance with AUC metric

--------------------------------------------------------------------------------

16. JOBLIB (joblib)
    ------------------------------------------------------------------------
    Purpose: Efficient serialization of Python objects (especially NumPy arrays)
    
    Functions Used:
    - joblib.dump()        : Save model to file
    - joblib.load()        : Load model from file
    
    Used In: train.py, retrain_model.py
    
    Why: Serialize trained sklearn models to disk for later use in predictions


================================================================================
                          DRIFT DETECTION MODULES
================================================================================

17. EVIDENTLY (evidently)
    ------------------------------------------------------------------------
    Purpose: ML model monitoring and data drift detection
    
    Classes Used:
    
    From evidently.report:
    - Report               : Container for drift analysis metrics
      Methods: .run(), .save_html(), .save_json(), .as_dict()
    
    From evidently.metrics:
    - DatasetDriftMetric   : Detect overall dataset drift
    - ColumnDriftMetric    : Detect per-column drift
    
    Used In: detect_drift.py
    
    Why: Core library for statistical drift detection using various tests
         (chi-square, KS-test, etc.) to compare reference vs current distributions
    
    Key Results Extracted:
    - dataset_drift        : Boolean indicating if drift detected
    - number_of_columns    : Total columns analyzed
    - number_of_drifted_columns : Count of drifted columns
    - share_of_drifted_columns : Percentage of columns with drift
    - drift_score          : Per-column drift score
    - stattest_name        : Statistical test used (chi2, ks, etc.)


================================================================================
                          DATA SOURCE MODULES
================================================================================

18. KAGGLE API (kaggle)
    ------------------------------------------------------------------------
    Purpose: Download datasets from Kaggle.com
    
    Classes/Functions Used:
    
    From kaggle.api.kaggle_api_extended:
    - KaggleApi            : API client for Kaggle
      Methods: .authenticate(), .dataset_download_files()
    
    Used In: load_data.py
    
    Why: Automatically download Telco Customer Churn dataset from Kaggle
    
    Configuration:
    - Requires kaggle.json file with API credentials in secrets/ folder
    - Set KAGGLE_CONFIG_DIR environment variable to secrets folder path


================================================================================
                              MODULE SUMMARY TABLE
================================================================================

| Module           | Category        | Primary Purpose                        |
|------------------|-----------------|----------------------------------------|
| os               | Standard Lib    | File/directory operations              |
| sys              | Standard Lib    | Command-line arguments                 |
| json             | Standard Lib    | JSON parsing                           |
| base64           | Standard Lib    | Image encoding for HTML                |
| webbrowser       | Standard Lib    | Open browser                           |
| subprocess       | Standard Lib    | Run external scripts                   |
| shutil           | Standard Lib    | File copy operations                   |
| http.server      | Standard Lib    | Web server                             |
| urllib.parse     | Standard Lib    | URL parsing                            |
| pandas           | Data Science    | Data manipulation                      |
| numpy            | Data Science    | Numerical operations                   |
| matplotlib       | Visualization   | Static charts                          |
| seaborn          | Visualization   | Statistical plots                      |
| sklearn          | ML              | Model training & evaluation            |
| joblib           | ML              | Model serialization                    |
| evidently        | Drift Detection | Statistical drift analysis             |
| kaggle           | Data Source     | Dataset download                       |


================================================================================
                              VERSION REQUIREMENTS
================================================================================

Key version constraints (from requirements.txt):

- Python >= 3.10
- evidently == 0.4.33     (Critical: requires pydantic v1)
- pydantic == 1.10.26     (Required for evidently compatibility)
- pandas >= 2.0
- numpy >= 1.24
- scikit-learn >= 1.0
- matplotlib >= 3.7
- seaborn >= 0.12
- joblib >= 1.3


================================================================================
                              FILE-MODULE MAPPING
================================================================================

detect_drift.py:
  os, sys, webbrowser, base64, pandas, matplotlib, seaborn, evidently

web_pipeline.py:
  os, json, subprocess, sys, base64, webbrowser, shutil, http.server,
  urllib.parse, pandas, numpy

retrain_model.py:
  os, pandas, shutil, joblib, sklearn

load_data.py:
  os, pandas, kaggle

preprocess.py:
  pandas, numpy

train.py:
  os, pandas, joblib, sklearn


================================================================================
                              END OF DOCUMENT
================================================================================
